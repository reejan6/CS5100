{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load in Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel awful about it too because it s my job ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im alone i feel awful</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ive probably mentioned this before but i reall...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i was feeling a little low few days back</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i beleive that i am much more sensitive to oth...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416804</th>\n",
       "      <td>that was what i felt when i was finally accept...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416805</th>\n",
       "      <td>i take every day as it comes i m just focussin...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416806</th>\n",
       "      <td>i just suddenly feel that everything was fake</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416807</th>\n",
       "      <td>im feeling more eager than ever to claw back w...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416808</th>\n",
       "      <td>i give you plenty of attention even when i fee...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416809 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text emotions\n",
       "0       i feel awful about it too because it s my job ...  sadness\n",
       "1                                   im alone i feel awful  sadness\n",
       "2       ive probably mentioned this before but i reall...      joy\n",
       "3                i was feeling a little low few days back  sadness\n",
       "4       i beleive that i am much more sensitive to oth...     love\n",
       "...                                                   ...      ...\n",
       "416804  that was what i felt when i was finally accept...      joy\n",
       "416805  i take every day as it comes i m just focussin...     fear\n",
       "416806      i just suddenly feel that everything was fake  sadness\n",
       "416807  im feeling more eager than ever to claw back w...      joy\n",
       "416808  i give you plenty of attention even when i fee...  sadness\n",
       "\n",
       "[416809 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = pd.read_pickle(\"merged_training.pkl\")\n",
    "text_df = text_df.reset_index(drop = True)\n",
    "text_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'feel',\n",
       " 'awful',\n",
       " 'about',\n",
       " 'it',\n",
       " 'too',\n",
       " 'because',\n",
       " 'it',\n",
       " 's',\n",
       " 'my',\n",
       " 'job',\n",
       " 'to',\n",
       " 'get',\n",
       " 'him',\n",
       " 'in',\n",
       " 'a',\n",
       " 'position',\n",
       " 'to',\n",
       " 'succeed',\n",
       " 'and',\n",
       " 'it',\n",
       " 'just',\n",
       " 'didn',\n",
       " 't',\n",
       " 'happen',\n",
       " 'here']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store data by words\n",
    "data_by_words = []\n",
    "# loop through texts\n",
    "for i in text_df['text']:\n",
    "    # get words, tokenize\n",
    "    value = nltk.word_tokenize(i)\n",
    "    data_by_words.append(value)\n",
    "data_by_words[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get Document Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271015015, 400544400)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(sentences = data_by_words, vector_size = 100)\n",
    "model.train(data_by_words, total_examples = len(data_by_words), epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format(\"word2vec.model\", binary = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45779\n",
      "(416808, 100)\n"
     ]
    }
   ],
   "source": [
    "embeddings_word_data = []\n",
    "# for each document\n",
    "track_count = 0\n",
    "for i in data_by_words:\n",
    "    text = []\n",
    "    # for each word in doc\n",
    "    for j in i:\n",
    "        # if word in model vocab get the embedding\n",
    "        if j in model.wv.key_to_index:\n",
    "            text.append(model.wv[j])\n",
    "    # average embeddings across all word embeddings\n",
    "    if len(text) != 0:\n",
    "        text = np.mean(text, axis = 0)\n",
    "        embeddings_word_data.append(text)\n",
    "    else:\n",
    "        print(track_count)\n",
    "    track_count+=1\n",
    "embeddings_word_data = np.array(embeddings_word_data)\n",
    "print(embeddings_word_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, val, test\n",
    "labelencoder = LabelEncoder()\n",
    "y = list(text_df['emotions'])\n",
    "del y[45779]\n",
    "y = labelencoder.fit_transform(y)\n",
    "\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(embeddings_word_data, y, test_size=0.2)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save embeddings\n",
    "np.save('text_embeddings_train.npy', X_train)\n",
    "np.save('text_embeddings_val.npy', X_val)\n",
    "np.save('text_embeddings_test.npy', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save labels\n",
    "with open(\"train_y.pkl\", \"wb\") as file:\n",
    "    pickle.dump(y_train, file)\n",
    "    \n",
    "with open(\"val_y.pkl\", \"wb\") as file:\n",
    "    pickle.dump(y_val, file)\n",
    "    \n",
    "with open(\"test_y.pkl\", \"wb\") as file:\n",
    "    pickle.dump(y_test, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
